{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "### run cleaning notebook to avoid saving it as a csv\n",
    "# %run Cleaning_EDA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Cleaning Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run cleaning notebook to avoid saving it as a csv\n",
    "%run Cleaning_EDA.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y variables:\n",
    "total_costs_label.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame\n",
    "y = total_costs_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear as baseline\n",
    "# lasso regression\n",
    "# gradient boost\n",
    "# random forest\n",
    "# knn\n",
    "# svm\n",
    "\n",
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Linear Regression as the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_preds = lin_reg.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(lin_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, lin_preds)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, lin_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, lin_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Linear Regression Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, lin_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alg = Lasso.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_preds = lasso_alg.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(lasso_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, lasso_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(y_test, lasso_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, lasso_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Lasso Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, lasso_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place elsewhere or use within each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search\n",
    "\n",
    "\n",
    "\n",
    "# Use a Gradient Boosting algorithm\n",
    "alg = GradientBoostingRegressor()\n",
    "\n",
    "# Try these hyperparameter values\n",
    "params = {\n",
    " 'learning_rate': [0.1, 0.5, 1.0],\n",
    " 'n_estimators' : [50, 100, 150]\n",
    " }\n",
    "\n",
    "# Find the best hyperparameter combination to optimize the R2 metric\n",
    "score = make_scorer(r2_score)\n",
    "gridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "model=gridsearch.best_estimator_\n",
    "print(model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest regressor using GridSearch\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "rf_grid = GridSearchCV(rf_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", rf_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "rf_model=rf_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(rf_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, rf_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(y_test, rf_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, rf_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Random Forest Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, rf_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting regressor using GridSearch\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "gb_grid = GridSearchCV(gb_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gb_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "gb_model=gb_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(gb_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, gb_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(y_test, gb_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, gb_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Random Forest Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, gb_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor using GridSearch\n",
    "# want multiple runs of multiple Ks\n",
    "\n",
    "kn_model = KNeighborRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "kn_grid = GridSearchCV(kn_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "kn_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", kn_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "kn_model1=kn_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor using GridSearch\n",
    "# want multiple runs of multiple Ks\n",
    "\n",
    "kn_model = KNeighborRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "kn_grid = GridSearchCV(kn_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "kn_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", kn_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "kn_model2=kn_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN regressor using GridSearch\n",
    "# want multiple runs of multiple Ks\n",
    "\n",
    "kn_model = KNeighborRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "kn_grid = GridSearchCV(kn_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "kn_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", kn_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "kn_model3=kn_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_preds = kn_model'#'.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(kn_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, kn_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(y_test, kn_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, kn_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Random Forest Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, kn_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = kn_model.kneighbors_graph(X_train)\n",
    "A.toarray()\n",
    "print(kn_model.predict([[1.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiple runs\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "neigh.fit(X, y)\n",
    "\n",
    "print(neigh.predict([[1.5]]))\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=1)\n",
    "neigh.fit(samples)\n",
    "\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "neigh.fit(X)\n",
    "\n",
    "A = neigh.kneighbors_graph(X)\n",
    "A.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting regressor using GridSearch\n",
    "gb_model = GradientBoostingRegressor()\n",
    "\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "gb_grid = GridSearchCV(gb_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gb_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "gb_model=gb_grid.best_estimator_\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(gb_preds)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, gb_preds)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(y_test, gb_preds)\n",
    "print('R2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, gb_preds)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Random Forest Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, gb_preds, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SV regressor using GridSearch\n",
    "linear_svr = svm.SVR(kernel='linear')\n",
    "linear_svr.kernel\n",
    "\n",
    "rbf_svr = svm.SVR(kernel='rbf')\n",
    "rbf_svr.kernel\n",
    "\n",
    "poly_svr = svm.SVR(kernel='poly')\n",
    "poly_svr.kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SV regressor using GridSearch\n",
    "linear_svr = svm.SVR(kernel='linear')\n",
    "linear_svr.kernel\n",
    "\n",
    "rbf_svr = svm.SVR(kernel='rbf')\n",
    "rbf_svr.kernel\n",
    "\n",
    "poly_svr = svm.SVR(kernel='poly')\n",
    "poly_svr.kernel\n",
    "\n",
    "# need to create a set of parameters for each model\n",
    "# need to run a grid search for each set of parameters and each model\n",
    "params = {\n",
    "    '': []\n",
    "    '': []\n",
    "}\n",
    "\n",
    "# Optimizing for R2\n",
    "score = make_scorer(r2_score)\n",
    "gb_grid = GridSearchCV(gb_model, params, scoring=score, cv=5, return_train_score=True)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gb_grid.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "gb_model=gb_grid.best_estimator_\n",
    "print(model, \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "linear_svr = svm.SVR(kernel='linear')\n",
    "linear_svr.kernel\n",
    "\n",
    "rbf_svr = svm.SVR(kernel='rbf')\n",
    "rbf_svr.kernel\n",
    "\n",
    "poly_svr = svm.SVR(kernel='poly')\n",
    "poly_svr.kernel\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
    "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
    "               coef0=1)\n",
    "\n",
    "# #############################################################################\n",
    "# Look at the results\n",
    "lw = 2\n",
    "\n",
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "kernel_label = ['RBF', 'Linear', 'Polynomial']\n",
    "model_color = ['m', 'c', 'g']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
    "for ix, svr in enumerate(svrs):\n",
    "    axes[ix].plot(X, svr.fit(X, y).predict(X), color=model_color[ix], lw=lw,\n",
    "                  label='{} model'.format(kernel_label[ix]))\n",
    "    axes[ix].scatter(X[svr.support_], y[svr.support_], facecolor=\"none\",\n",
    "                     edgecolor=model_color[ix], s=50,\n",
    "                     label='{} support vectors'.format(kernel_label[ix]))\n",
    "    axes[ix].scatter(X[np.setdiff1d(np.arange(len(X)), svr.support_)],\n",
    "                     y[np.setdiff1d(np.arange(len(X)), svr.support_)],\n",
    "                     facecolor=\"none\", edgecolor=\"k\", s=50,\n",
    "                     label='other training data')\n",
    "    axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "                    ncol=1, fancybox=True, shadow=True)\n",
    "\n",
    "fig.text(0.5, 0.04, 'data', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, 'target', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
